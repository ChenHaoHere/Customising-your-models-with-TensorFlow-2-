{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Model subclassing and custom training loops",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChenHaoHere/Customising-your-models-with-TensorFlow-2-/blob/master/Model_subclassing_and_custom_training_loops.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhj0O_7Fe8IB",
        "colab_type": "code",
        "outputId": "0104f84d-4dd5-4475-98b8-e131c5c4faad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfdlfOQFe8IE",
        "colab_type": "text"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvNT-9JLe8IF",
        "colab_type": "text"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85r3GZxpe8IF",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Model subclassing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHC1D5Nce8IG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7K2EBNqe8II",
        "colab_type": "text"
      },
      "source": [
        "#### Create a simple model using the model subclassing API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2srcdC_e8II",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the model\n",
        "\n",
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dense_1 = Dense(64, activation='relu')\n",
        "    self.dense_2 = Dense(10)\n",
        "    self.dropout = Dropout(0.4)\n",
        "\n",
        "  def call(self, inputs, training=True):\n",
        "    x = self.dense_1(inputs)\n",
        "    if training:\n",
        "      x = self.dropout(x)\n",
        "    return self.dense_2(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYtUWiwae8IL",
        "colab_type": "code",
        "outputId": "14ccf5fa-1982-439e-8aea-09de9a5764d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# Print the model summary\n",
        "\n",
        "model = MyModel()\n",
        "model(tf.random.uniform([5, 16]))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  1088      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  650       \n",
            "=================================================================\n",
            "Total params: 1,738\n",
            "Trainable params: 1,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9DNY7Pre8IN",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giAP_Eqwe8IO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ko4JVbJe8IQ",
        "colab_type": "text"
      },
      "source": [
        "#### Create custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SpikGBMe8IQ",
        "colab_type": "code",
        "outputId": "6eae1bf5-069e-41e6-8ec9-d185b3005506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# Create a custom layer\n",
        "\n",
        "class MyLayer(Layer):\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.w = self.add_weight(shape=(input_dim, units), initializer='random_normal')\n",
        "    self.b = self.add_weight(shape=(units,), initializer='zeros')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "dense_layer = MyLayer(3,5)\n",
        "x = tf.ones((1, 5))\n",
        "print(dense_layer(x))\n",
        "print(dense_layer.weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.11859568 0.12629911 0.08923965]], shape=(1, 3), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
            "array([[ 0.0407519 , -0.04449302, -0.03844872],\n",
            "       [ 0.01403059,  0.07156275,  0.06113951],\n",
            "       [ 0.0094814 ,  0.03644079, -0.03776183],\n",
            "       [-0.01381715,  0.05363858,  0.07398784],\n",
            "       [ 0.06814893,  0.00915002,  0.03032284]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9NjGJGbe8IT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify trainable weights\n",
        "\n",
        "class MyLayer(Layer):\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.w = self.add_weight(shape=(input_dim, units), initializer='random_normal', trainable=False)\n",
        "    self.b = self.add_weight(shape=(units,), initializer='zeros', trainable=False)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "dense_layer = MyLayer(3,5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J27w0OLce8IV",
        "colab_type": "code",
        "outputId": "ed44625b-f461-47f3-992e-9119537e6b53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print('trainable weights:', len(dense_layer.trainable_weights))\n",
        "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainable weights: 0\n",
            "non-trainable weights: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU3GaekBe8IX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a custom layer to accumulate means of output values\n",
        "\n",
        "class MyLayerMean(Layer):\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayerMean, self).__init__()\n",
        "    self.w = self.add_weight(shape=(input_dim, units), initializer='random_normal')\n",
        "    self.b = self.add_weight(shape=(units,), initializer='zeros')\n",
        "    self.sum_activation = tf.Variable(initial_value=tf.zeros((units, )), trainable=False)\n",
        "    self.number_call = tf.Variable(initial_value=0, trainable=False)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    activations = tf.matmul(inputs, self.w) + self.b\n",
        "    self.sum_activation.assign_add(tf.reduce_sum(activations, axis=0))\n",
        "    self.number_call.assign_add(inputs.shape[0])\n",
        "    print(self.sum_activation, ' ', tf.cast(self.number_call, tf.float32))\n",
        "    return activations, self.sum_activation / tf.cast(self.number_call, tf.float32)\n",
        "\n",
        "dense_layer = MyLayerMean(3,5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9Kyd8bRe8IZ",
        "colab_type": "code",
        "outputId": "cfc44b62-f8e1-4429-c43b-08cb629b5c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Test the layer\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([ 0.06908275, -0.09463295,  0.02846216], dtype=float32)>   tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "[ 0.06908275 -0.09463295  0.02846216]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTopKlene8Ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Dropout layer as a custom layer\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyAb8elge8Ie",
        "colab_type": "text"
      },
      "source": [
        "#### Implement the custom layers into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82Db29eie8Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the model using custom layers with the model subclassing API\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2, units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3, units_2)\n",
        "        self.softmax = Sotfmax()\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENnwM22Me8Ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate a model object\n",
        "\n",
        "model = MyModel(64,10000,64,46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QFXC-3Fe8Ii",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITuZCPZQe8Ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQWofBvme8Il",
        "colab_type": "text"
      },
      "source": [
        "#### Create synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzsyWUN_e8Il",
        "colab_type": "code",
        "outputId": "8ee9c64f-a5c9-4090-f141-99bc0389cc86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Create data from a noise contaminated linear model\n",
        "\n",
        "def MakeNoisyData(m, b, n=20):\n",
        "    x = tf.random.uniform(shape=(n,))\n",
        "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
        "    y = m * x + b + noise\n",
        "    return x, y\n",
        "\n",
        "m=1\n",
        "b=2\n",
        "x_train, y_train = MakeNoisyData(m,b)\n",
        "plt.plot(x_train, y_train, 'b.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3560237240>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA6dzdJne8In",
        "colab_type": "text"
      },
      "source": [
        "#### Define a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf4Jw-pPe8In",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Moqpv7Z_e8Ip",
        "colab_type": "code",
        "outputId": "58ba5d64-e982-4e52-c4d3-a23485cb4d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# Build a custom layer for the linear regression model\n",
        "\n",
        "class LinearLayer(Layer):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.m = self.add_weight(shape=(1,),\n",
        "                  initializer='random_normal')\n",
        "    self.b = self.add_weight(shape=(1,),\n",
        "                  initializer='random_normal')\n",
        "  def call(self, inputs):\n",
        "    return self.m*inputs+self.b\n",
        "\n",
        "linear_regression = LinearLayer()\n",
        "\n",
        "print(linear_regression(x_train))\n",
        "print(linear_regression.weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[0.07225019 0.09646001 0.0668438  0.10095213 0.05163085 0.0471513\n",
            " 0.07031094 0.09680766 0.04750572 0.09653416 0.07956442 0.06432985\n",
            " 0.06527267 0.07772222 0.06209304 0.08746277 0.05310456 0.05067974\n",
            " 0.09776211 0.05607738], shape=(20,), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.07263627], dtype=float32)>, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.03289065], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L7IpZh4e8Ir",
        "colab_type": "text"
      },
      "source": [
        "#### Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPf6Vqq8e8Ir",
        "colab_type": "code",
        "outputId": "92c7b221-ef49-4979-fa9a-122985ce5486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Define the mean squared error loss function\n",
        "\n",
        "def SquaredError(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
        "\n",
        "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
        "print(\"Starting loss\", starting_loss.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting loss 5.989774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZwTTLHWe8It",
        "colab_type": "text"
      },
      "source": [
        "#### Train and plot the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j25Sp0QPe8It",
        "colab_type": "code",
        "outputId": "ec586099-7ccc-41f9-f4fe-84c26c7711bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Implement a gradient descent training loop for the linear regression model\n",
        "\n",
        "lr = 0.05\n",
        "steps = 20\n",
        "for i in range(steps):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = linear_regression(x_train)\n",
        "    loss = SquaredError(y_train, predictions)\n",
        "  gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
        "\n",
        "  linear_regression.m.assign_sub(lr * gradients[0])\n",
        "  linear_regression.b.assign_sub(lr * gradients[1])\n",
        "\n",
        "  print(\"Step %d, Loss %f\" % (i, loss.numpy()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss 5.989774\n",
            "Step 1, Loss 4.531621\n",
            "Step 2, Loss 3.429172\n",
            "Step 3, Loss 2.595653\n",
            "Step 4, Loss 1.965462\n",
            "Step 5, Loss 1.488998\n",
            "Step 6, Loss 1.128760\n",
            "Step 7, Loss 0.856397\n",
            "Step 8, Loss 0.650471\n",
            "Step 9, Loss 0.494776\n",
            "Step 10, Loss 0.377059\n",
            "Step 11, Loss 0.288054\n",
            "Step 12, Loss 0.220759\n",
            "Step 13, Loss 0.169876\n",
            "Step 14, Loss 0.131403\n",
            "Step 15, Loss 0.102312\n",
            "Step 16, Loss 0.080314\n",
            "Step 17, Loss 0.063680\n",
            "Step 18, Loss 0.051100\n",
            "Step 19, Loss 0.041586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gaQOd8be8Iw",
        "colab_type": "code",
        "outputId": "6389292c-f980-4742-d04b-7bfbc96c60ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "# Plot the learned regression model\n",
        "\n",
        "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
        "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
        "\n",
        "plt.plot(x_train, y_train, 'b.')\n",
        "\n",
        "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
        "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m:1,  trained m:[1.0478415]\n",
            "b:2,  trained b:[1.790181]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f34fbc4f7f0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV5KdLs9e8Iy",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## Custom training loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUZqg8c_e8Iy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCavS7KGe8I0",
        "colab_type": "text"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Pd106Je8I0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEzeGH6Ve8I2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the custom layers and model\n",
        "\n",
        "class MyLayer(Layer):\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.w = self.add_weight(shape=(input_dim, units), initializer='random_normal')\n",
        "    self.b = self.add_weight(shape=(units,), initializer='zeros')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2, units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3, units_2)\n",
        "        self.softmax = Sotfmax()\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8F0PA-Ve8I4",
        "colab_type": "text"
      },
      "source": [
        "#### Load the reuters dataset and define the class_names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hMBr7iOe8I5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
        "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
        "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
        "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKPLGf2Ie8I6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the class of the first sample\n",
        "\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VAc1_e8e8I9",
        "colab_type": "text"
      },
      "source": [
        "#### Get the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5xLulMUe8I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Reuters word index\n",
        "\n",
        "word_to_index = reuters.get_word_index()\n",
        "\n",
        "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
        "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HP1h228e8I_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the first data example sentence\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duMmf0s_e8JB",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJPHl2JSe8JB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function that encodes the data into a 'bag of words' representation\n",
        "\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros((len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(train_data)\n",
        "x_test = bag_of_words(test_data)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4bxeNM9e8JD",
        "colab_type": "text"
      },
      "source": [
        "#### Define the loss function and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNz1sORbe8JD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the categorical cross entropy loss and Adam optimizer\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss(model, x, y, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
        "    y_ = model(x)\n",
        "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivJa4j-oe8JF",
        "colab_type": "text"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3K1mnuHe8JF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to compute the forward and backward pass\n",
        "\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muw6uLfTe8JH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "    \n",
        "    \n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWYh9m06e8JK",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAYqVo3Se8JK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Dataset object for the test set\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DicGWdP4e8JM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Collect average loss and accuracy\n",
        "\n",
        "epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMUTc4bIe8JO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loop over the test set and print scores\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "for x, y in test_dataset:\n",
        "    # Optimize the model\n",
        "    loss_value = loss(model, x, y, weight_decay)    \n",
        "    # Compute current loss\n",
        "    epoch_loss_avg(loss_value)  \n",
        "    # Compare predicted label to actual label\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
        "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-vMMRo6e8JP",
        "colab_type": "text"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCEKTV5Ie8JP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the training loss and accuracy\n",
        "\n",
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaGw8K7le8JR",
        "colab_type": "text"
      },
      "source": [
        "#### Predict from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHuyoSeGe8JR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the model prediction for an example input\n",
        "\n",
        "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
        "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
        "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITetPXphe8JT",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGq2ougZe8JT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcS3qgqre8JW",
        "colab_type": "text"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMpyVbL2e8JW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize a new model\n",
        "\n",
        "class MyLayer(Layer):\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.w = self.add_weight(shape=(input_dim, units), initializer='random_normal')\n",
        "    self.b = self.add_weight(shape=(units,), initializer='zeros')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2, units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3, units_2)\n",
        "        self.softmax = Sotfmax()\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "model = MyModel(64, 64, 46)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrH6gaJ6e8JZ",
        "colab_type": "text"
      },
      "source": [
        "#### Redefine the grad function using the @tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlrMhdHGe8JZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the @tf.function decorator\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivSfC9kje8Jb",
        "colab_type": "text"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyRczt0te8Jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-run the training loop\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x05BGWIe8Je",
        "colab_type": "text"
      },
      "source": [
        "#### Print the autograph code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htrHMnQ1e8Je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use tf.autograph.to_code to see the generated code\n",
        "\n",
        "print(tf.autograph.to_code(grad.python_function))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}